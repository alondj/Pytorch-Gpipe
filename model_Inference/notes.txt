control flow inference:
1.  need to know how are layers connnected to each other

2.  there is a bug where the second scopeName in a nn.Sequential is used for all layers after it in the sequence
    maybe fix it bug is in torch/onnx/utils.py/_optimize_graph/139 if commented out all fine

3.  graph contains inputs, outputs, parameters, and, buffers followed by nodes. 
    3.1. inputs parameters and buffers are at the start and can be accessed via #torch._C.Graph.inputs
    3.2. outputs are specified by the return keyword (last line of the graph)  can be accessed via #torch._C.Graph.outputs
    3.3. nodes are the intermediate ops in the network can be layers or atomic ops.
         they are identified by their scopeName and node number accessed via #torch._C.Node.scopeName torch._C.Node.inputs.

4.  traversal of the graph is possible and scopeNames can connect us to the relevant layers in the model.
    so we can traverse the graph and build a new graph which will include our time measurements so we could partition it

5. each node has a scope name and we also have the scopeNames that we acquired from the profiler
   if a node has a prefix from the profiler than it's not an atomic op(arithmetic)

6. arithmetic nodes will be added to the graph

7. layer nodes with the sampe scopeName should be merged

8. layers a,b are connected if there is a route from a to b

graph partition:
1. partition based on execution time (forward + backward) and layer size(parameters buffers possibly input output and gradients)

2. each node is an operation or operand(inputs/buffers/parameters/operation's output), edges represent the flow of data in the network


partition restrictions:
1. graph must not have back edges or cycles.
1. partition must be as balanced as possible.
2. every partition must be sequential possibly multiple branches.
3. if nodes flow to a common op, their outputs must be placed on the same gpu as the op (that gpu will contain the output).





graph optimizations:
1. merge all nodes under the same scope. 
2. remove nodes representing constants they server no purpose.
3. remove parameters and buffers that were accounted for by the profiler.
6. #TODO decide on weighting functional
7. #TODO ensure outputs are on the same device
8. #TODO arithmetic ops must reside on the same deveice that created them
9. #TODO if we decide ops must be on the same gpu we can merge them to the same node